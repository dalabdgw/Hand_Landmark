{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "533aaacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install natsort\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import natsort # 파일 숫자 정렬용 라이브러리\n",
    "import os\n",
    "import librosa\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e04e5cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = 30 # 1초 = 30 frame\n",
    "skeleton_count = 42 # 42개 ( 21 * 2 ( 왼손 & 오른손 ))\n",
    "coord_count = 3 # X, Y, Z\n",
    "\n",
    "n_mfcc = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11c2e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_extracted_features = np.empty((0,n_mfcc), float)\n",
    "dir_extracted_skeletons = np.empty((0,frame_count, coord_count, skeleton_count), float)\n",
    "dir_extracted_sec = []\n",
    "dir_extracted_coord = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d70efa",
   "metadata": {},
   "source": [
    "## 0. MFCC 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d42ead3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2022/03/implementing-audio-classification-project-using-deep-learning/\n",
    "#https://stackoverflow.com/questions/52841335/how-can-i-pad-wav-file-to-specific-length\n",
    "from librosa.util import fix_length\n",
    "from librosa import load\n",
    "from tqdm import tqdm\n",
    "\n",
    "def features_extractor(file):\n",
    "    #load the file (audio)\n",
    "    file_name = file\n",
    "    sf = 44100 # sampling frequency of wav file\n",
    "    \n",
    "    audio, sample_rate = librosa.load(file_name, sr=sf, mono=True) # mono=True converts stereo audio to mono\n",
    "        \n",
    "    #we extract mfcc'\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, n_mfcc=20, sr=sf) ## --> n_mfcc : 20 ~ 50\n",
    "    #print(\"mfccs_features\",mfccs_features.shape)\n",
    "\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0) ## 평균으로 출력\n",
    "    \n",
    "    #print(\"mfccs_scaled_features\", mfccs_scaled_features.shape)\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d500a3",
   "metadata": {},
   "source": [
    "## 1. feature 데이터 가공하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b33c7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor_dir(directory):\n",
    "    file_list = natsort.natsorted(os.listdir(directory))\n",
    "\n",
    "    extracted_sec = []\n",
    "\n",
    "    extracted_features=[]\n",
    "    extracted_len_features=[]\n",
    "    file_total_len = 1 # feature_input 길이 ex). 1초, 2초\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for filename in file_list:\n",
    "        filename_split = re.split(r'-|\\.wav', filename)\n",
    "        sec = int(filename_split[1])\n",
    "        extracted_sec.append(sec)\n",
    "    \n",
    "        file_name = os.path.join(directory, filename) ## 만약에 2초마다 붙이고 싶으면\n",
    "        # printf(filename)\n",
    "        data = features_extractor(file_name)\n",
    "        extracted_len_features = np.concatenate((extracted_len_features, data))\n",
    "        count+=1\n",
    "    \n",
    "        if (count == file_total_len):\n",
    "            extracted_features.append(extracted_len_features)\n",
    "        \n",
    "            extracted_len_features=[]\n",
    "            count = 0\n",
    "\n",
    "    extracted_features = np.array(extracted_features)\n",
    "    return extracted_features, extracted_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a525fa5a",
   "metadata": {},
   "source": [
    "### 1.1 features_audio_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc8ce94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio_dir_list = [\"music1_audio_ground_truth_wav\", \"music2_audio_ground_truth_wav\",\"music3_audio_ground_truth_wav\"]\n",
    "audio_dir_list = [\"music3_audio_ground_truth_wav\"]\n",
    "\n",
    "for dir_name in audio_dir_list:\n",
    "        extracted_features, extracted_sec = features_extractor_dir(dir_name)\n",
    "        \n",
    "        dir_extracted_features = np.append(dir_extracted_features,extracted_features, axis=0)\n",
    "        dir_extracted_sec.append(extracted_sec) # extracted_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba69519",
   "metadata": {},
   "source": [
    "## 2. skeleton 데이터 가공하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "952215f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeleton_extractor_dir(directory, extracted_sec_len):\n",
    "    skeleton = pd.read_csv(directory)\n",
    "\n",
    "    extracted_skeleton=[] ### 궁금한게 초 길이 ## 다음 순차적으로 데이터 이어 붙이기 해야할 것같음\n",
    "    extracted_coord = []\n",
    "    \n",
    "    start_sec = 0 # 시작 sec\n",
    "    end_sec = extracted_sec_len\n",
    "\n",
    "    interval = 0\n",
    "    start_frame = (start_sec+interval) * 30 # 실제 csv : ( row = 2부터 시작 ) // 한 칸씩 떼기\n",
    "    end_frame = (end_sec+interval) * 30\n",
    "    \n",
    "    extracted_4dim_skeleton=np.zeros((frame_count,coord_count,skeleton_count), float)\n",
    "    \n",
    "    for frame_num in range(start_frame, end_frame, frame_count): # start_frame ~ end_frame\n",
    "        extracted_total_skeleton=[]\n",
    "        extracted_3dim_skeleton = np.zeros((30,3),float)\n",
    "\n",
    "        start_index = 0\n",
    "        end_index = skeleton.shape[1]\n",
    "        for index in range(start_index, end_index, 3):\n",
    "            extracted_2dim_list = skeleton.iloc[frame_num:(frame_num+frame_count), index:(index+3)]\n",
    "        \n",
    "            coord_name = re.split(r'_LX|_LY|_LX|_RX|_RY|_RZ', list(extracted_2dim_list)[0])[0]\n",
    "            \n",
    "            extracted_coord.append(coord_name)\n",
    "            extracted_3dim_skeleton = np.append(extracted_3dim_skeleton,np.array(extracted_2dim_list), axis=0)\n",
    "            \n",
    "        extracted_3dim_skeleton = np.delete(extracted_3dim_skeleton,range(0,frame_count), axis=0 )\n",
    "    \n",
    "        extracted_3dim_skeleton = extracted_3dim_skeleton.reshape(frame_count,coord_count,skeleton_count)\n",
    "        extracted_4dim_skeleton = np.append(extracted_4dim_skeleton, extracted_3dim_skeleton, axis=0)\n",
    "        \n",
    "    extracted_4dim_skeleton = np.delete(extracted_4dim_skeleton,range(0,frame_count), axis=0 )\n",
    "    extracted_4dim_skeleton = extracted_4dim_skeleton.reshape(end_sec, frame_count, coord_count,skeleton_count)\n",
    "\n",
    "    \n",
    "    return extracted_4dim_skeleton, extracted_coord\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d42682f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_dir_list = ['music1_hand_result_ground_truth.csv','music2_hand_result_ground_truth.csv','music3_hand_result_ground_truth.csv']\n",
    "video_dir_list = ['music3_hand_result_ground_truth.csv']\n",
    "video_index = 0\n",
    "\n",
    "for dir_name in video_dir_list:\n",
    "    extracted_sec_len = len(dir_extracted_sec[video_index])\n",
    "    extracted_dim_skeleton, extracted_coord = skeleton_extractor_dir(dir_name, extracted_sec_len)\n",
    "    \n",
    "    dir_extracted_skeletons = np.append(dir_extracted_skeletons, extracted_dim_skeleton, axis=0)\n",
    "    dir_extracted_coord.append(extracted_coord)\n",
    "    \n",
    "    video_index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbfd368",
   "metadata": {},
   "source": [
    "### skeleton 데이터 차원 축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44dba308",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ( 65, 30, 3, 42 ) --> ( 65, 3780 )\n",
    "extracted_contraction_skeleton = []\n",
    "total_sec = dir_extracted_skeletons.shape[0]\n",
    "skeleton_row_count = frame_count*coord_count*skeleton_count\n",
    "\n",
    "\n",
    "for i in range(total_sec):\n",
    "    contraction_skeleton = np.ravel(dir_extracted_skeletons[i], order='C')\n",
    "    extracted_contraction_skeleton = np.append(extracted_contraction_skeleton, contraction_skeleton, axis = 0)\n",
    "        \n",
    "extracted_contraction_skeleton = extracted_contraction_skeleton.reshape(total_sec, skeleton_row_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f0ac7",
   "metadata": {},
   "source": [
    "## 3. Train, Test 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "956cb3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  (150, 20)\n",
      "output :  (150, 3780)\n"
     ]
    }
   ],
   "source": [
    "## input (mfcc audio) : extracted_features ( sec, features ) \n",
    "## output (skeleton video) : extracted_contraction_skeleton ( sec, frame_count * coord_count * skeleton_count)\n",
    "print(\"input : \", dir_extracted_features.shape)\n",
    "print(\"output : \", extracted_contraction_skeleton.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46280b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def train_test_normalize(input_data, output_data):\n",
    "    # create training and test set \n",
    "    \n",
    "    inputs = input_data\n",
    "    outputs = output_data\n",
    "    \n",
    "    #####################################################################################################\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(inputs)\n",
    "    inputs = scaler.transform(inputs)\n",
    "    #####################################################################################################\n",
    "    \n",
    "    #####################################################################################################\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(outputs)\n",
    "    outputs = scaler.transform(outputs)\n",
    "    #####################################################################################################\n",
    "    \n",
    "    ### Train Test Split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train,X_test,y_train,y_test=train_test_split(inputs,outputs,test_size=0.2,random_state=7)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train) # 2차원 변경\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1 )) # LSTM 모델을 위해 3차원 변경\n",
    "    \n",
    "    #####################################################################################################\n",
    "    y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[1], 1 )) # LSTM 모델을 위해 3차원 변경\n",
    "    #####################################################################################################\n",
    "    \n",
    "    X_test, y_test = np.array(X_test), np.array(y_test) # 2차원 변경\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1 )) # LSTM 모델을 위해 3차원 변경\n",
    "    #####################################################################################################\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0],y_test.shape[1], 1 )) # LSTM 모델을 위해 3차원 변경\n",
    "    #####################################################################################################\n",
    "    \n",
    "    return X_train, y_train , X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55661493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 20)\n",
      "(120, 3780)\n",
      "(30, 20)\n",
      "(30, 3780)\n",
      "X_train :  (120, 20, 1)  y_train :  (120, 3780, 1)\n",
      "X_test :  (30, 20, 1)  y_test :  (30, 3780, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_normalize(dir_extracted_features, extracted_contraction_skeleton)\n",
    "print(\"X_train : \",X_train.shape, \" y_train : \", y_train.shape)\n",
    "\n",
    "print(\"X_test : \", X_test.shape, \" y_test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7268656",
   "metadata": {},
   "source": [
    "# Reconstruction LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd72717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cord's source is from below site\n",
    "# https://machinelearningmastery.com/lstm-autoencoders/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ee40ff",
   "metadata": {},
   "source": [
    "## Installization Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "850f2797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mathjax\n",
    "# pip install jupyter_server_mathjax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67e124dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter server extension enable --py jupyter_server_mathjax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b93ad3",
   "metadata": {},
   "source": [
    "## 4. LSTM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a47e0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# lstm autoencoder recreate sequence\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "871dd2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(X_train, y_train, X_test):\n",
    "    # create a model\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "    from keras import optimizers\n",
    "    \n",
    "    repeat_count = y_train.shape[1] ## repeat_vector count 지정해주기 ex. X_train.shape[0]\n",
    "    \n",
    "    #####################################################################################################\n",
    "    ########################                           AutoEncoder\n",
    "    #####################################################################################################\n",
    "    \n",
    "    # The LSTM architecture\n",
    "    my_LSTM_model = Sequential()\n",
    "    \n",
    "    my_LSTM_model.add(LSTM(units = 100, activation = 'relu',input_shape = (X_train.shape[1],1)))\n",
    "    #my_LSTM_model.add(LSTM(units = 100, activation = 'relu',batch_input_shape = (X_train.shape[0], X_train.shape[1],1)))\n",
    "    my_LSTM_model.add(RepeatVector(repeat_count))\n",
    "    \n",
    "    my_LSTM_model.add(LSTM(units = 100, activation = 'relu',return_sequences = True))\n",
    "    my_LSTM_model.add(TimeDistributed(Dense(1)))\n",
    "    \n",
    "    #####################################################################################################\n",
    "    \n",
    "    # Compiling \n",
    "    my_LSTM_model.compile(loss='mae', optimizer='adam', metrics=['mse'])\n",
    "    plot_model(my_LSTM_model, show_shapes=True, to_file='model2_auto_encoder_shinhyeong.png')\n",
    "    \n",
    "    my_LSTM_model.summary()\n",
    "    \n",
    "    #my_LSTM_model.fit(X_train, y_train, epochs = 300, verbose = 0) # batch_size = 150,\n",
    "    #LSTM_prediction = my_LSTM_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    return my_LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "359dc4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model_Run(X_train, y_train, X_test, LSTM_model):\n",
    "    \n",
    "    # model training\n",
    "    # batch_size = 512\n",
    "    epoch = 50\n",
    "    verbose_value = 1\n",
    "    \n",
    "    # Fitting to the training set \n",
    "    LSTM_model.fit(X_train, y_train, epochs=epoch, verbose=verbose_value)\n",
    "    \n",
    "    LSTM_prediction = my_LSTM_model.predict(X_test, verbose=verbose_value)\n",
    "    print(\"[LSTM_prediction] : \",LSTM_prediction)\n",
    "    return LSTM_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7becab3c",
   "metadata": {},
   "source": [
    "## 5. LSTM 모델 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6d78c16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 3780, 100)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 3780, 100)         80400     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 3780, 1)           101       \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_LSTM_model = LSTM_model(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd1870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 42s 348ms/step - loss: 0.4046 - mse: 0.2112\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 41s 344ms/step - loss: 0.2648 - mse: 0.1056\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 40s 330ms/step - loss: 0.2040 - mse: 0.0622\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 39s 327ms/step - loss: 0.1861 - mse: 0.0514\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 43s 359ms/step - loss: 0.1902 - mse: 0.0547\n",
      "Epoch 6/50\n"
     ]
    }
   ],
   "source": [
    "LSTM_prediction = LSTM_model_Run(X_train, y_train, X_test,my_LSTM_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8711849c",
   "metadata": {},
   "source": [
    "## 6. Prediction LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e31bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_for_visualization(dimension_array): # dimension_array : 3-dim\n",
    "    dimension_array = dimension_array[:, :, 0]\n",
    "    total_sec = dimension_array.shape[0]\n",
    "\n",
    "    # 3780 = frame_count * coord_count + skeleton_count // division\n",
    "    start_num = 0\n",
    "    end_num = frame_count * coord_count * skeleton_count\n",
    "    \n",
    "    sec_data_array = []\n",
    "    \n",
    "    for second in range(total_sec):\n",
    "        frame_coord_count = frame_count*coord_count\n",
    "        data_array_col = 0\n",
    "        \n",
    "        data_array = np.zeros((frame_count, coord_count*skeleton_count), float)\n",
    "        \n",
    "        for frame_coord_index in range(start_num, end_num, frame_coord_count):\n",
    "            frame_array = dimension_array[second, frame_coord_index:(frame_coord_index+frame_coord_count)]\n",
    "            data_array_row = 0\n",
    "            for coord_index in range(0, frame_coord_count, coord_count):\n",
    "                coord_array = frame_array[coord_index: (coord_index+coord_count)]\n",
    "                data_array[data_array_row][data_array_col:(data_array_col+coord_count)] = coord_array\n",
    "                \n",
    "                data_array_row+=1\n",
    "                #print(data_array_row,\" , \",data_array_col,\" , \",(data_array_col+coord_count))\n",
    "            \n",
    "            data_array_col+=coord_count\n",
    "            \n",
    "        sec_data_array.append(data_array)\n",
    "        \n",
    "    sec_data_array_result = np.reshape(sec_data_array, (total_sec ,frame_count, coord_count*skeleton_count)) # LSTM 모델을 위해 3차원 변경\n",
    "\n",
    "            \n",
    "    return sec_data_array_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25451bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_result = convert_for_visualization(y_test)\n",
    "LSTM_prediction_result = convert_for_visualization(LSTM_prediction)\n",
    "\n",
    "print(\"y_test: \",y_test_result.shape, \"prediction: \", LSTM_prediction_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433df63f",
   "metadata": {},
   "source": [
    "### 6-0. 데이터 ( y_test, prediction )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc80e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_total_count = coord_count * skeleton_count # 126\n",
    "\n",
    "# data -- # 30 프레임 단위로 있음 len(y_test_frame_list) = 30\n",
    "y_test_coord_list = np.zeros((frame_count, skeleton_total_count), list)\n",
    "lstm_prediction_coord_list = np.zeros((frame_count, skeleton_total_count), list)\n",
    "\n",
    "# point\n",
    "y_test_points_list = []\n",
    "lstm_prediction_points_list = []\n",
    "\n",
    "# hand ( 126, 13, 30 )\n",
    "y_test_hand_list = []\n",
    "lstm_prediction_hand_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a1697",
   "metadata": {},
   "source": [
    "### 6-1. 그래프 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(y_test, preds, nIndex ):\n",
    "    \n",
    "    actual_pred = pd.DataFrame(columns = ['actual_value', 'prediction'])\n",
    "    actual_pred['actual_value'] = y_test[:, nIndex ] # nIndex 번째 행\n",
    "    actual_pred['prediction'] = preds[:, nIndex]\n",
    "\n",
    "    import tensorflow as tf\n",
    "    import matplotlib.pyplot\n",
    "    \n",
    "    m = tf.keras.metrics.MeanSquaredError()\n",
    "    m.update_state(np.array(actual_pred['actual_value']), np.array(actual_pred['prediction']))\n",
    "    \n",
    "    # plot()\n",
    "    #actual_pred.plot()\n",
    "    \n",
    "    return (m.result().numpy(), actual_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab820a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_coord_division(y_test_skeleton_list, lstm_prediction_skeleton_list):\n",
    "    \n",
    "    y_test_frame_list = [] # 30 프레임 단위로 있음 len(y_test_frame_list) = 30\n",
    "    lstm_prediction_frame_list = []\n",
    "    \n",
    "    for frame_index in range(frame_count):\n",
    "        \n",
    "        _, actual_pred = actual_pred_plot(y_test_skeleton_list, lstm_prediction_skeleton_list, frame_index)\n",
    "    \n",
    "        y_test_frame_result          = actual_pred['actual_value']\n",
    "        lstm_prediction_frame_result = actual_pred['prediction']\n",
    "    \n",
    "        y_test_frame_list.append(y_test_frame_result)\n",
    "        lstm_prediction_frame_list.append(lstm_prediction_frame_result)\n",
    "        \n",
    "    return y_test_frame_list, lstm_prediction_frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21275844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_coord_division(y_test_coord_list, lstm_prediction_coord_list, y_test_skeleton_list, lstm_prediction_skeleton_list, skeleton_index ):\n",
    "    \n",
    "    for frame_index in range(frame_count):\n",
    "        \n",
    "        _, actual_pred = actual_pred_plot(y_test_skeleton_list, lstm_prediction_skeleton_list, frame_index)\n",
    "    \n",
    "        y_test_frame_result          = actual_pred['actual_value']\n",
    "        lstm_prediction_frame_result = actual_pred['prediction']\n",
    "        \n",
    "        y_test_coord_list[frame_index, skeleton_index]          = y_test_frame_result\n",
    "        lstm_prediction_coord_list[frame_index, skeleton_index] = lstm_prediction_frame_result\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c2429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for skeleton_index in range(skeleton_total_count): # skeleton_count 42\n",
    "    y_test_skeleton_list          = y_test_result[ :, :, skeleton_index]\n",
    "    lstm_prediction_skeleton_list = LSTM_prediction_result[ :, :, skeleton_index]\n",
    "    \n",
    "    frame_coord_division(y_test_coord_list, lstm_prediction_coord_list, y_test_skeleton_list, lstm_prediction_skeleton_list, skeleton_index )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b864b2c8",
   "metadata": {},
   "source": [
    "### 6-2. 정확도 수치 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f9e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "\n",
    "score = my_LSTM_model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test mse:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc78e90",
   "metadata": {},
   "source": [
    "### 6-3 Hand visualization ( 3D )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2f3791",
   "metadata": {},
   "source": [
    "1. <br/>\n",
    "    - WRIST - 각각 FINGER들의 첫번째와 연결<br/>\n",
    "    - FINGER들끼리 연결<br/>\n",
    "\n",
    "2. <br/>\n",
    "    - WRIST 0<br/>\n",
    "    - THUMB 1, 2, 3, 4<br/>\n",
    "    - INDEX 5, 6, 7, 8<br/>\n",
    "    - MIDDLE 9, 10, 11, 12<br/>\n",
    "    - RING 13, 14, 15, 16<br/>\n",
    "    - PINKY 17, 18, 19, 20<br/>\n",
    "\n",
    "3. <br/>\n",
    "    - 0 - 1 - 2 - 3 - 4, <br/>\n",
    "    - 0 - 5 - 6 - 7 - 8,<br/>\n",
    "    - 0 - 9 - 10 - 11 - 12,<br/>\n",
    "    - 0 - 13 - 14 - 15 - 16,<br/>\n",
    "    - 0 - 17 - 18 - 19 - 20<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00878526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_division(coord_list):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    z_list = []\n",
    "    \n",
    "    for i in range(len(coord_list)): # len(coord_list) : 126개\n",
    "        if i % 3 ==0:\n",
    "            x_list.append(coord_list[i][3]) # 일단 왜 3 인지 잘 모르겠음\n",
    "        elif i % 3 ==1:\n",
    "            y_list.append(coord_list[i][3])\n",
    "        else :\n",
    "            z_list.append(coord_list[i][3])\n",
    "    \n",
    "    points_list = np.array([x_list, y_list, z_list])\n",
    "    #points_frame_list.append(points_list)\n",
    "    \n",
    "    return points_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_visualization(points_list):\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = plt.axes(projection = '3d')\n",
    "    \n",
    "    # points(x, y, z)\n",
    "    x = points_list[0]\n",
    "    y = points_list[1]\n",
    "    z = points_list[2]\n",
    "    \n",
    "    ax.scatter3D(x[:20], y[:20], z[:20], s=40, c='#1f77b4')\n",
    "    ax.invert_xaxis()\n",
    "    \n",
    "    ax.plot([x[0], x[1], x[2], x[3], x[4]],  ## 이 쪽은 색깔을 좀 바꿔야할 것같음\n",
    "            [y[0], y[1], y[2], y[3], y[4]], \n",
    "            [z[0], z[1], z[2], z[3], z[4]])\n",
    "    ax.plot([x[0], x[5], x[6], x[7], x[8]], \n",
    "            [y[0], y[5], y[6], y[7], y[8]], \n",
    "            [z[0], z[5], z[6], z[7], z[8]])\n",
    "    ax.plot([x[0], x[9], x[10], x[11], x[12]], \n",
    "            [y[0], y[9], y[10], y[11], y[12]], \n",
    "            [z[0], z[9], z[10], z[11], z[12]])\n",
    "    ax.plot([x[0], x[13], x[14], x[15], x[16]], \n",
    "            [y[0], y[13], y[14], y[15], y[16]], \n",
    "            [z[0], z[13], z[14], z[15], z[16]])\n",
    "    ax.plot([x[0], x[17], x[18], x[19], x[20]], \n",
    "            [y[0], y[17], y[18], y[19], y[20]], \n",
    "            [z[0], z[17], z[18], z[19], z[20]])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b011bf",
   "metadata": {},
   "source": [
    "#### 6-3-0. 데이터 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddeff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for frame_index in range(frame_count):\n",
    "    \n",
    "    # coord_division(skeleton_list) -- skeleton_list( 30, 126 )\n",
    "    y_test_points_list          = coord_division(y_test_coord_list[frame_index])\n",
    "    lstm_prediction_points_list = coord_division(lstm_prediction_coord_list[frame_index])\n",
    "    \n",
    "    # point restore\n",
    "    y_test_hand_list.append(y_test_points_list)\n",
    "    lstm_prediction_hand_list.append(lstm_prediction_points_list)\n",
    "    \n",
    "    # hand_visualization\n",
    "    hand_visualization(y_test_points_list)\n",
    "    hand_visualization(lstm_prediction_points_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a2e15",
   "metadata": {},
   "source": [
    "## 7. PCA coefficient\n",
    "\n",
    "* https://www.kaggle.com/code/bobaaayoung/pca-lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce41772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def plt_visualize_PCA(evr):\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(np.arange(1, len(evr) + 1), np.cumsum(evr*100), \"-o\")\n",
    "    plt.title(\"PCA\", fontsize=15)\n",
    "    plt.xlabel(\"n_components\",fontsize=15)\n",
    "    plt.ylabel(\"(%)\",fontsize=15)\n",
    "    plt.xticks(range(1,len(evr),2),fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "def Data_PCA(input_data):\n",
    "    scaler = preprocessing.StandardScaler().fit(input_data)\n",
    "    \n",
    "    X_scaled = scaler.transform(input_data)\n",
    "    X_scaled = pd.DataFrame(X_scaled)\n",
    "    \n",
    "    estimator_pca = PCA(n_components=None)\n",
    "    estimator_pca.fit(X_scaled)\n",
    "    evr = estimator_pca.explained_variance_ratio_\n",
    "    \n",
    "    plt_visualize_PCA(evr) ## plt_visualize\n",
    "    \n",
    "def Apply_Data_PCA(input_data, n_component):\n",
    "    scaler = preprocessing.StandardScaler().fit(input_data)\n",
    "    \n",
    "    X_scaled = scaler.transform(input_data)\n",
    "    X_scaled = pd.DataFrame(X_scaled)\n",
    "    \n",
    "    pca = PCA(n_components=n_component)\n",
    "    input_data_pca = pca.fit_transform(X_scaled)\n",
    "    input_data_pca = pd.DataFrame(input_data_pca)\n",
    "    \n",
    "    print('PCA dimension Reduction：',X_scaled.shape,'-->',input_data_pca.shape)\n",
    "    return input_data_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af86c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_PCA(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae397412",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_pca = Apply_Data_PCA(extracted_features,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61d55cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_PCA(extracted_contraction_skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887475fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_pca = Apply_Data_PCA(extracted_contraction_skeleton,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_normalize(input_data_pca, output_data_pca)\n",
    "print(\"X_train : \",X_train.shape, \" y_train : \", y_train.shape)\n",
    "\n",
    "print(\"X_test : \", X_test.shape, \" y_test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3cd629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bbb67a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
